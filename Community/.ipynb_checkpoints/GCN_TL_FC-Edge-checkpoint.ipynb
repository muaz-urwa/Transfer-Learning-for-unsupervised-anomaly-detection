{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import NNConv\n",
    "\n",
    "from sklearn.mixture import GaussianMixture \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['date'] = pd.to_datetime(data.date)\n",
    "    print('Days: ',len(set(data.date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='amount', index=['date'],\n",
    "                    columns=['start_id','end_id'], aggfunc=np.sum, fill_value=0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/home/urwa/Documents/Projects/AnomalyDetection/Pipeline/data/'\n",
    "dataFile = '20190402_TaipeiEdgesDatewise.csv'\n",
    "events_data =dataDir+'TaipeiEvents.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (7374816, 5)\n",
      "Days:  638\n"
     ]
    }
   ],
   "source": [
    "file = dataDir + dataFile\n",
    "dataRaw = loadData(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataIn =  pd.pivot_table(dataRaw, values='amount', index=['date'],\n",
    "#                     columns=['end_id'], aggfunc=np.sum, fill_value=0)\n",
    "# dataIn.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BL01</td>\n",
       "      <td>BL01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BL01</td>\n",
       "      <td>BL01</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 start_id end_id       date  amount\n",
       "0           0     BL01   BL01 2017-01-01    70.0\n",
       "1           1     BL01   BL01 2017-01-02    40.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataOut =  pd.pivot_table(dataRaw, values='amount', index=['date'],\n",
    "#                     columns=['start_id'], aggfunc=np.sum, fill_value=0)\n",
    "# dataOut.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = np.stack((dataOut.values, dataIn.values),-1)\n",
    "# matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEdge = getTimeSeries(dataRaw)\n",
    "#matrix = dataEdge.values\n",
    "matrix = np.load('communityAggregatedMatrix.npy')\n",
    "matrix = matrix.astype(float)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(matrix.shape[1]):\n",
    "#         matrix[:, i] = (matrix[:, i] - np.mean(matrix[:, i])) / (np.std(matrix[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(matrix.shape[0]):\n",
    "        matrix[i,:] = (matrix[i,:] - np.mean(matrix[i,:])) / (np.std(matrix[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = list(set(dataRaw.start_id))\n",
    "n= 10 #len(stations)\n",
    "edge_index = [[a//n,a%n] for a in range(n*n)]\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = list(dataEdge.index)\n",
    "DOW = list(pd.to_datetime(dataEdge.index.values).dayofweek)\n",
    "DOW = ((np.array(DOW) == 5) | (np.array(DOW) == 6)).astype(int)\n",
    "DOW[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[100, 1], edge_index=[2, 100], x=[10, 1], y=[1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList = []\n",
    "\n",
    "for i in range(len(DOW)):\n",
    "    x = torch.tensor(np.ones((n,1)), dtype=torch.float)\n",
    "    y = torch.tensor(np.array([DOW[i]]), dtype=torch.long)\n",
    "    e = torch.tensor(matrix[i].reshape(matrix.shape[1],1), dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous(),y=y,edge_attr=e)\n",
    "    dataList.append(data)\n",
    "\n",
    "dataList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "featureDim = 1\n",
    "hiddenDim = [8,16,20]\n",
    "num_edge_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNConv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.conv1 = GCNConv(featureDim, hiddenDim[0])\n",
    "        self.conv1Lin = nn.Linear(1, featureDim * hiddenDim[0])\n",
    "        self.conv1 = NNConv(featureDim, hiddenDim[0],self.conv1Lin)\n",
    "        #self.conv1 = NNConv(featureDim, hiddenDim[0],nn.Linear(1, 1000))\n",
    "        \n",
    "        #self.conv2 = GCNConv(hiddenDim[0], hiddenDim[1])\n",
    "        self.conv2Lin = nn.Linear(1, hiddenDim[0]*hiddenDim[1])\n",
    "        self.conv2 = NNConv(hiddenDim[0], hiddenDim[1],self.conv2Lin)\n",
    "        \n",
    "        self.linear1 = nn.Linear(n*hiddenDim[1], hiddenDim[2])\n",
    "        self.linear2 = nn.Linear(hiddenDim[2], n_classes)\n",
    "\n",
    "        self.init_weights(self.linear1)\n",
    "        self.init_weights(self.linear2)\n",
    "        self.init_weights(self.conv1Lin)\n",
    "        self.init_weights(self.conv2Lin)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index,edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        #print(x.shape)\n",
    "        #print(x[0])\n",
    "        x = self.conv1(x, edge_index,edge_attr)\n",
    "        #print(x.shape)\n",
    "        #print(x[0])\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index,edge_attr)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1,n*hiddenDim[1])\n",
    "        #print(x.shape)\n",
    "        x = self.linear1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.linear2(x)\n",
    "        #print(x.shape)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "    def init_weights(self,m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def representation(self, x):\n",
    "        x, edge_index,edge_attr = data.x, data.edge_index,data.edge_attr\n",
    "        x = self.conv1(x, edge_index,edge_attr)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index,edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1,n*hiddenDim[1])\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "#data = dataset[0].to(device)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss:388.4520\n",
      "epoch [2/200], loss:184.7511\n",
      "epoch [3/200], loss:147.3527\n",
      "epoch [4/200], loss:130.9510\n",
      "epoch [5/200], loss:119.4655\n",
      "epoch [6/200], loss:112.8412\n",
      "epoch [7/200], loss:108.5162\n",
      "epoch [8/200], loss:104.9295\n",
      "epoch [9/200], loss:101.8394\n",
      "epoch [10/200], loss:99.2785\n",
      "epoch [11/200], loss:96.6827\n",
      "epoch [12/200], loss:95.3531\n",
      "epoch [13/200], loss:93.4233\n",
      "epoch [14/200], loss:91.8623\n",
      "epoch [15/200], loss:90.3995\n",
      "epoch [16/200], loss:88.7728\n",
      "epoch [17/200], loss:88.7954\n",
      "epoch [18/200], loss:87.2309\n",
      "epoch [19/200], loss:86.1458\n",
      "epoch [20/200], loss:85.2580\n",
      "epoch [21/200], loss:84.6035\n",
      "epoch [22/200], loss:83.4948\n",
      "epoch [23/200], loss:83.6350\n",
      "epoch [24/200], loss:82.7301\n",
      "epoch [25/200], loss:82.2469\n",
      "epoch [26/200], loss:81.7070\n",
      "epoch [27/200], loss:81.3029\n",
      "epoch [28/200], loss:81.0326\n",
      "epoch [29/200], loss:80.4590\n",
      "epoch [30/200], loss:80.2800\n",
      "epoch [31/200], loss:79.6748\n",
      "epoch [32/200], loss:79.3099\n",
      "epoch [33/200], loss:79.2315\n",
      "epoch [34/200], loss:78.5355\n",
      "epoch [35/200], loss:78.2548\n",
      "epoch [36/200], loss:78.1200\n",
      "epoch [37/200], loss:77.6861\n",
      "epoch [38/200], loss:77.3789\n",
      "epoch [39/200], loss:77.0531\n",
      "epoch [40/200], loss:76.5407\n",
      "epoch [41/200], loss:76.3822\n",
      "epoch [42/200], loss:76.1750\n",
      "epoch [43/200], loss:75.7095\n",
      "epoch [44/200], loss:75.4849\n",
      "epoch [45/200], loss:75.2675\n",
      "epoch [46/200], loss:74.9316\n",
      "epoch [47/200], loss:74.7393\n",
      "epoch [48/200], loss:74.5232\n",
      "epoch [49/200], loss:74.2233\n",
      "epoch [50/200], loss:74.0209\n",
      "epoch [51/200], loss:73.8182\n",
      "epoch [52/200], loss:73.5224\n",
      "epoch [53/200], loss:73.3802\n",
      "epoch [54/200], loss:73.0791\n",
      "epoch [55/200], loss:72.8723\n",
      "epoch [56/200], loss:72.8124\n",
      "epoch [57/200], loss:72.4760\n",
      "epoch [58/200], loss:72.1892\n",
      "epoch [59/200], loss:72.0186\n",
      "epoch [60/200], loss:71.9196\n",
      "epoch [61/200], loss:71.6141\n",
      "epoch [62/200], loss:71.3985\n",
      "epoch [63/200], loss:71.1775\n",
      "epoch [64/200], loss:71.0318\n",
      "epoch [65/200], loss:70.8220\n",
      "epoch [66/200], loss:70.5788\n",
      "epoch [67/200], loss:70.4221\n",
      "epoch [68/200], loss:70.2831\n",
      "epoch [69/200], loss:69.9755\n",
      "epoch [70/200], loss:69.9308\n",
      "epoch [71/200], loss:69.7425\n",
      "epoch [72/200], loss:69.4956\n",
      "epoch [73/200], loss:69.2668\n",
      "epoch [74/200], loss:69.3564\n",
      "epoch [75/200], loss:69.1710\n",
      "epoch [76/200], loss:68.9521\n",
      "epoch [77/200], loss:68.7287\n",
      "epoch [78/200], loss:68.5804\n",
      "epoch [79/200], loss:68.3575\n",
      "epoch [80/200], loss:68.3027\n",
      "epoch [81/200], loss:67.9312\n",
      "epoch [82/200], loss:68.0003\n",
      "epoch [83/200], loss:67.6413\n",
      "epoch [84/200], loss:67.7594\n",
      "epoch [85/200], loss:67.6465\n",
      "epoch [86/200], loss:67.1751\n",
      "epoch [87/200], loss:66.7865\n",
      "epoch [88/200], loss:66.6159\n",
      "epoch [89/200], loss:66.5136\n",
      "epoch [90/200], loss:66.2721\n",
      "epoch [91/200], loss:66.0205\n",
      "epoch [92/200], loss:65.8492\n",
      "epoch [93/200], loss:65.8185\n",
      "epoch [94/200], loss:65.5142\n",
      "epoch [95/200], loss:65.4435\n",
      "epoch [96/200], loss:65.3509\n",
      "epoch [97/200], loss:65.0808\n",
      "epoch [98/200], loss:65.0337\n",
      "epoch [99/200], loss:64.8284\n",
      "epoch [100/200], loss:64.6377\n",
      "epoch [101/200], loss:64.5104\n",
      "epoch [102/200], loss:64.4218\n",
      "epoch [103/200], loss:64.1324\n",
      "epoch [104/200], loss:64.1246\n",
      "epoch [105/200], loss:63.9075\n",
      "epoch [106/200], loss:63.8773\n",
      "epoch [107/200], loss:63.7307\n",
      "epoch [108/200], loss:63.4758\n",
      "epoch [109/200], loss:63.3562\n",
      "epoch [110/200], loss:63.2482\n",
      "epoch [111/200], loss:63.1142\n",
      "epoch [112/200], loss:62.9790\n",
      "epoch [113/200], loss:62.8867\n",
      "epoch [114/200], loss:62.6581\n",
      "epoch [115/200], loss:62.5413\n",
      "epoch [116/200], loss:62.3881\n",
      "epoch [117/200], loss:62.1980\n",
      "epoch [118/200], loss:62.1538\n",
      "epoch [119/200], loss:61.9741\n",
      "epoch [120/200], loss:61.8710\n",
      "epoch [121/200], loss:61.6857\n",
      "epoch [122/200], loss:61.6243\n",
      "epoch [123/200], loss:61.3555\n",
      "epoch [124/200], loss:61.1650\n",
      "epoch [125/200], loss:61.0957\n",
      "epoch [126/200], loss:61.0762\n",
      "epoch [127/200], loss:60.7874\n",
      "epoch [128/200], loss:60.6357\n",
      "epoch [129/200], loss:60.5899\n",
      "epoch [130/200], loss:60.3265\n",
      "epoch [131/200], loss:60.2782\n",
      "epoch [132/200], loss:60.1563\n",
      "epoch [133/200], loss:60.0152\n",
      "epoch [134/200], loss:59.7541\n",
      "epoch [135/200], loss:59.7103\n",
      "epoch [136/200], loss:59.5315\n",
      "epoch [137/200], loss:59.4329\n",
      "epoch [138/200], loss:59.2271\n",
      "epoch [139/200], loss:59.1222\n",
      "epoch [140/200], loss:59.0603\n",
      "epoch [141/200], loss:59.3085\n",
      "epoch [142/200], loss:58.8737\n",
      "epoch [143/200], loss:58.7189\n",
      "epoch [144/200], loss:58.6101\n",
      "epoch [145/200], loss:58.3743\n",
      "epoch [146/200], loss:58.3249\n",
      "epoch [147/200], loss:58.1714\n",
      "epoch [148/200], loss:58.1683\n",
      "epoch [149/200], loss:57.8525\n",
      "epoch [150/200], loss:57.8245\n",
      "epoch [151/200], loss:57.6447\n",
      "epoch [152/200], loss:57.4254\n",
      "epoch [153/200], loss:57.3773\n",
      "epoch [154/200], loss:57.2708\n",
      "epoch [155/200], loss:57.0724\n",
      "epoch [156/200], loss:56.8334\n",
      "epoch [157/200], loss:56.8293\n",
      "epoch [158/200], loss:56.5886\n",
      "epoch [159/200], loss:56.6204\n",
      "epoch [160/200], loss:56.4800\n",
      "epoch [161/200], loss:56.2932\n",
      "epoch [162/200], loss:56.2839\n",
      "epoch [163/200], loss:55.9912\n",
      "epoch [164/200], loss:56.0206\n",
      "epoch [165/200], loss:55.8561\n",
      "epoch [166/200], loss:55.8035\n",
      "epoch [167/200], loss:55.6097\n",
      "epoch [168/200], loss:55.4866\n",
      "epoch [169/200], loss:55.4606\n",
      "epoch [170/200], loss:55.3124\n",
      "epoch [171/200], loss:55.1786\n",
      "epoch [172/200], loss:54.8747\n",
      "epoch [173/200], loss:54.9635\n",
      "epoch [174/200], loss:54.7130\n",
      "epoch [175/200], loss:54.8417\n",
      "epoch [176/200], loss:54.5465\n",
      "epoch [177/200], loss:54.4403\n",
      "epoch [178/200], loss:54.3745\n",
      "epoch [179/200], loss:54.2470\n",
      "epoch [180/200], loss:54.1271\n",
      "epoch [181/200], loss:54.0913\n",
      "epoch [182/200], loss:53.8370\n",
      "epoch [183/200], loss:53.8320\n",
      "epoch [184/200], loss:53.7811\n",
      "epoch [185/200], loss:53.5993\n",
      "epoch [186/200], loss:53.5352\n",
      "epoch [187/200], loss:53.3156\n",
      "epoch [188/200], loss:53.1810\n",
      "epoch [189/200], loss:53.2067\n",
      "epoch [190/200], loss:53.1651\n",
      "epoch [191/200], loss:52.9901\n",
      "epoch [192/200], loss:52.8500\n",
      "epoch [193/200], loss:52.6437\n",
      "epoch [194/200], loss:52.6849\n",
      "epoch [195/200], loss:52.4341\n",
      "epoch [196/200], loss:52.5416\n",
      "epoch [197/200], loss:52.2805\n",
      "epoch [198/200], loss:51.9675\n",
      "epoch [199/200], loss:52.0732\n",
      "epoch [200/200], loss:51.8814\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epochLoss = 0\n",
    "    for data in dataList:\n",
    "        #data.view(1,-1,-1)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "#         print(out.shape)\n",
    "#         print(data.y.shape)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epochLoss += loss.item()\n",
    "    \n",
    "#     if epoch == 500:\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=5e-4)\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "    .format(epoch + 1, num_epochs, np.mean(epochLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y = DOW\n",
    "    predList = []\n",
    "    for data in dataList:\n",
    "        data = data.to(device)\n",
    "        pred = model(data).cpu().numpy()\n",
    "        predList.append(np.argmax(pred))\n",
    "    \n",
    "    print('Accuracy: {:.4f}'.format( np.sum(np.array(predList) == np.array(y)) / len(predList) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = np.empty((matrix.shape[0],hiddenDim[2]))\n",
    "#representationR = np.empty((matrix.shape[0],hiddenDim[2]))\n",
    "prediction = np.empty((matrix.shape[0],n_classes))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(dataList):\n",
    "        data = data.to(device)\n",
    "        representation[i] = model.representation(data).cpu().numpy()\n",
    "        #representationR[i] = model.representationR(data).cpu().numpy()\n",
    "        prediction[i] = model(data).cpu().numpy()\n",
    "        predList.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import events data\n",
    "events_data =dataDir+'TaipeiEvents.csv'\n",
    "df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National holiday</td>\n",
       "      <td>Republic Day/New Year's Day observed</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>National holiday</td>\n",
       "      <td>Chinese New Year's Eve</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National holiday</td>\n",
       "      <td>Chinese New Year's Day</td>\n",
       "      <td>2017-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National holiday</td>\n",
       "      <td>Chinese New Year Holiday 1</td>\n",
       "      <td>2017-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National holiday</td>\n",
       "      <td>Chinese New Year Holiday 2</td>\n",
       "      <td>2017-01-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type                                  Name       Date\n",
       "0  National holiday  Republic Day/New Year's Day observed 2017-01-02\n",
       "1  National holiday                Chinese New Year's Eve 2017-01-27\n",
       "2  National holiday                Chinese New Year's Day 2017-01-28\n",
       "3  National holiday            Chinese New Year Holiday 1 2017-01-29\n",
       "4  National holiday            Chinese New Year Holiday 2 2017-01-30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidayDates = df_events[df_events.Type == 'National holiday'].Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidayDates = [str(d.date()) for d in holidayDates]\n",
    "dates = [str(d.date()) for d in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyIndex = [i for i,d in enumerate(dates) if d in holidayDates]\n",
    "len(anomalyIndex)\n",
    "indexBool = np.array([i in anomalyIndex for i in list(range(matrix.shape[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyDetection(y,pval = 0.2,iterN=5,n_com=1):\n",
    "    #index of regular (non-outlier points)\n",
    "    #rind=y[:,0]>-10 \n",
    "    rind = np.array(range(y.shape[0]))\n",
    "    \n",
    "    #clustering model\n",
    "    gm=GaussianMixture(n_components=n_com, n_init=100, max_iter=1000,random_state=0) \n",
    "    for i in range(iterN): #iterate\n",
    "        print('Iteration {}'.format(i+1))  \n",
    "        clustering=gm.fit(y[rind,:]) #fit EM clustering model excluding outliers\n",
    "        l=clustering.score_samples(y) #estimate likelihood for each point\n",
    "        Lthres=sorted(l)[int(len(l)*pval)] #anomaly threshold\n",
    "        rind0=0+rind\n",
    "        rind=l>Lthres #non-anomalous points\n",
    "        if all(rind==rind0):\n",
    "            print('Convergence in {} iterations'.format(i+1))\n",
    "            break\n",
    "    return l < Lthres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(reducedMatrix,threshHolds,iterN=5,n_com=1):\n",
    "    results = []\n",
    "    for th in threshHolds:\n",
    "        #th = thres/100\n",
    "        print(\"Threshhold: \",th)\n",
    "        outliers = anomalyDetection(reducedMatrix,th,iterN,n_com)\n",
    "\n",
    "        tpr = sum(outliers & indexBool)/sum(indexBool)\n",
    "        fpr = sum(outliers & ~indexBool)/sum(~indexBool)\n",
    "        precision = sum(outliers & indexBool)/sum(outliers)\n",
    "\n",
    "        F1 = 2 * (precision * tpr) / (precision + tpr)\n",
    "\n",
    "        res = {'Cat':'Global', 'th':th, 'TPR':tpr, 'FPR':fpr, 'F1':F1, 'Precision':precision}\n",
    "        results.append(res)\n",
    "\n",
    "    resDf = pd.DataFrame(results)    \n",
    "    return resDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshHolds = [0.01, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold:  0.01\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Convergence in 2 iterations\n",
      "Threshhold:  0.03\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.04\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Convergence in 3 iterations\n",
      "Threshhold:  0.05\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Convergence in 3 iterations\n",
      "Threshhold:  0.06\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Convergence in 3 iterations\n",
      "Threshhold:  0.07\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.08\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.1\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.2\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.3\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.4\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.5\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.6\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.7\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.8\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Threshhold:  0.9\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n"
     ]
    }
   ],
   "source": [
    "Res1 = getResults(representation,threshHolds,iterN=5,n_com=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cat</th>\n",
       "      <th>F1</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>TPR</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.031199</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.164204</td>\n",
       "      <td>0.212598</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267652</td>\n",
       "      <td>0.146597</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.141119</td>\n",
       "      <td>0.579639</td>\n",
       "      <td>0.075916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.122105</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.107607</td>\n",
       "      <td>0.789819</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Global</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>0.894910</td>\n",
       "      <td>0.050523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cat        F1       FPR  Precision       TPR    th\n",
       "0   Global  0.228571  0.003284   0.666667  0.137931  0.01\n",
       "1   Global  0.500000  0.011494   0.631579  0.413793  0.03\n",
       "2   Global  0.444444  0.021346   0.480000  0.413793  0.04\n",
       "3   Global  0.500000  0.026273   0.483871  0.517241  0.05\n",
       "4   Global  0.567164  0.031199   0.500000  0.655172  0.06\n",
       "5   Global  0.547945  0.039409   0.454545  0.689655  0.07\n",
       "6   Global  0.500000  0.050903   0.392157  0.689655  0.08\n",
       "7   Global  0.500000  0.065681   0.365079  0.793103  0.10\n",
       "8   Global  0.346154  0.164204   0.212598  0.931034  0.20\n",
       "9   Global  0.254545  0.267652   0.146597  0.965517  0.30\n",
       "10  Global  0.204225  0.371100   0.113725  1.000000  0.40\n",
       "11  Global  0.166667  0.476190   0.090909  1.000000  0.50\n",
       "12  Global  0.141119  0.579639   0.075916  1.000000  0.60\n",
       "13  Global  0.122105  0.684729   0.065022  1.000000  0.70\n",
       "14  Global  0.107607  0.789819   0.056863  1.000000  0.80\n",
       "15  Global  0.096186  0.894910   0.050523  1.000000  0.90"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
